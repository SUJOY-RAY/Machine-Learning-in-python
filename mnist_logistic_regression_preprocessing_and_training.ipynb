{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6BuGfPQJb58ly8ztdaKF+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SUJOY-RAY/Machine-Learning-in-python/blob/main/mnist_logistic_regression_preprocessing_and_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fetching dataset**"
      ],
      "metadata": {
        "id": "EAlwP17-ROC9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "8zzC5nMyRHLt"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist=fetch_openml('mnist_784', as_frame=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6heIT3bRxZz",
        "outputId": "ad4e1e6f-5db4-4b57-e405-c831a651b5c8"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x,y=mnist['data'], mnist['target']"
      ],
      "metadata": {
        "id": "B9mb177BR4CQ"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HikJW7XaUz7l",
        "outputId": "8aee6ef0-8385-44a3-e181-fa2ce352ee4b"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reHk6y7-SRTT",
        "outputId": "7ee6a93b-72c2-4e24-f416-5bbea6e27e45"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "RtdjF5VySYiR"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09RwNSuyT6S3",
        "outputId": "6d63640b-743e-4958-8908-70bffda42555"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000,)"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "some_digit=x[1]\n",
        "some_digit_image=some_digit.reshape(28,28)  #reshape to plot it"
      ],
      "metadata": {
        "id": "4fWysl30SmD9"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "9I01vZkYWK6D"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "nh_cTD3YTii6"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(some_digit_image, cmap=matplotlib.cm.binary,interpolation='nearest')\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ukhdamf8VNJ7",
        "outputId": "e84aa4ee-f7b6-42b8-a0bc-0f1d456f9b93"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.5, 27.5, 27.5, -0.5)"
            ]
          },
          "metadata": {},
          "execution_count": 159
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[1] #numeric value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "6pxbBNnWVNHH",
        "outputId": "e39057f1-4b5f-41a6-fb30-4250285620ec"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=x[:7000]\n",
        "x_test=x[7000:]"
      ],
      "metadata": {
        "id": "yb_dZmI-VNDs"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=y[7000:8000]\n",
        "y_test=y[7000:8000]"
      ],
      "metadata": {
        "id": "XV6AnYmvVMx5"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "shuffle_index=np.random.permutation(500)\n",
        "x_train=x_train[shuffle_index]\n",
        "y_train=y_train[shuffle_index]"
      ],
      "metadata": {
        "id": "Z8fCl6uuVMtQ"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating a 2 detector**"
      ],
      "metadata": {
        "id": "LkewrhtSYWGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=y_train.astype(np.int8)\n",
        "y_test=y_train.astype(np.int8)\n",
        "y_train_1=(y_train==2)\n",
        "y_test_1=(y_test==2)"
      ],
      "metadata": {
        "id": "TCqyp7YtYULU"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16Rk_KvUYj4_",
        "outputId": "6a7b6fa1-86eb-4ed5-8294-f0c6df35ac9f"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False,  True, False, False,\n",
              "        True,  True, False, False, False, False, False, False, False,\n",
              "       False, False, False,  True, False, False, False, False,  True,\n",
              "       False,  True, False, False, False,  True, False, False, False,\n",
              "        True, False,  True, False, False, False, False, False,  True,\n",
              "        True, False,  True, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "        True,  True, False, False, False, False, False, False, False,\n",
              "       False, False, False,  True, False,  True,  True, False, False,\n",
              "       False, False, False, False, False, False,  True, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False,  True, False, False,  True,  True,\n",
              "       False, False, False,  True, False, False, False, False,  True,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False,  True, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False,  True,\n",
              "       False, False, False, False,  True, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False,  True, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False,  True, False, False,\n",
              "       False, False, False, False, False,  True, False,  True, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False,  True, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False,  True, False, False, False, False, False, False,\n",
              "       False,  True, False, False, False, False,  True,  True, False,\n",
              "        True, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False,  True, False, False,  True, False,\n",
              "       False, False, False, False,  True, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False,  True, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False,  True, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False,  True,  True, False, False,  True, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False,  True, False,\n",
              "       False, False, False, False,  True, False, False,  True, False,\n",
              "       False, False,  True, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False,  True, False,  True, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False,  True, False,  True, False])"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "eLopKKJvYm74"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf=LogisticRegression(max_iter=1000)"
      ],
      "metadata": {
        "id": "PvuB7ZGyZFTt"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(x_train,y_train_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "0g4e0cjxZK-L",
        "outputId": "e81df440-6c38-476f-91f0-516712b8552e"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000)"
            ],
            "text/html": [
              "<style>#sk-container-id-17 {color: black;background-color: white;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.predict([some_digit])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDOyb7CTZQRN",
        "outputId": "3c440f23-83af-4a8c-fb4a-fec473734498"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False])"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "a=cross_val_score(clf,x_train,y_train_1, cv=3, scoring=\"accuracy\")"
      ],
      "metadata": {
        "id": "4W8cH7ArcZGL"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.mean()"
      ],
      "metadata": {
        "id": "R7I9TiMRdKr1",
        "outputId": "db0afe6a-24fe-45f7-ffef-fd480ba1bbf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8139143399947093"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating a not 2 detector**"
      ],
      "metadata": {
        "id": "yp_CHCCbdjQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=y_train.astype(np.int8)\n",
        "y_test=y_train.astype(np.int8)\n",
        "y_train_1=(y_train==2)\n",
        "y_test_1=(y_test==2)"
      ],
      "metadata": {
        "id": "65xrF_d3dnS8"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "o4mc_qEIgIUM",
        "outputId": "33592c24-9047-4a1e-b2ba-17f06c6218d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 4, 5, 1, 7, 3, 8, 3, 6, 9, 3, 8, 9, 9, 7, 5, 0, 8, 6, 3, 7,\n",
              "       0, 4, 2, 6, 0, 2, 2, 5, 7, 7, 0, 6, 3, 9, 4, 8, 9, 2, 7, 5, 1, 4,\n",
              "       2, 5, 2, 8, 0, 8, 2, 4, 6, 0, 2, 3, 2, 6, 9, 1, 7, 4, 2, 2, 6, 2,\n",
              "       9, 1, 6, 1, 1, 5, 8, 8, 8, 5, 3, 0, 3, 1, 5, 2, 2, 7, 1, 4, 5, 1,\n",
              "       7, 1, 0, 9, 7, 2, 5, 2, 2, 6, 8, 0, 9, 1, 5, 7, 4, 2, 5, 3, 3, 0,\n",
              "       1, 6, 3, 6, 6, 4, 9, 6, 3, 7, 3, 2, 3, 1, 2, 2, 6, 1, 8, 2, 8, 9,\n",
              "       3, 8, 2, 9, 4, 5, 8, 6, 3, 4, 1, 8, 7, 2, 8, 9, 6, 1, 4, 8, 3, 4,\n",
              "       4, 4, 9, 5, 8, 7, 7, 2, 7, 7, 8, 5, 2, 9, 1, 0, 5, 9, 0, 6, 8, 9,\n",
              "       3, 8, 8, 1, 7, 6, 5, 0, 2, 7, 5, 3, 0, 9, 4, 3, 5, 8, 8, 1, 9, 3,\n",
              "       9, 8, 7, 7, 3, 6, 3, 9, 9, 0, 1, 7, 1, 1, 5, 2, 5, 6, 1, 9, 4, 1,\n",
              "       4, 2, 0, 2, 0, 9, 6, 5, 1, 1, 0, 7, 5, 5, 9, 8, 8, 7, 7, 0, 3, 0,\n",
              "       5, 1, 3, 5, 4, 0, 1, 4, 7, 8, 7, 0, 5, 6, 5, 8, 9, 2, 9, 1, 5, 8,\n",
              "       5, 6, 6, 7, 9, 7, 8, 6, 2, 7, 3, 0, 4, 0, 1, 4, 2, 7, 8, 1, 0, 2,\n",
              "       2, 4, 2, 1, 0, 3, 1, 3, 9, 6, 6, 8, 9, 3, 9, 0, 5, 1, 5, 7, 4, 8,\n",
              "       8, 8, 2, 7, 0, 2, 0, 6, 1, 4, 7, 2, 7, 1, 4, 5, 9, 3, 6, 7, 4, 9,\n",
              "       0, 8, 4, 7, 9, 3, 0, 7, 7, 8, 6, 9, 4, 5, 6, 9, 7, 9, 2, 3, 8, 1,\n",
              "       9, 8, 6, 0, 5, 1, 0, 7, 7, 0, 2, 0, 8, 7, 4, 0, 6, 9, 5, 3, 3, 0,\n",
              "       5, 0, 1, 8, 0, 1, 1, 1, 9, 5, 8, 3, 0, 6, 5, 2, 2, 8, 6, 2, 4, 8,\n",
              "       5, 5, 1, 4, 1, 9, 6, 3, 8, 5, 5, 1, 1, 8, 1, 3, 2, 9, 5, 8, 1, 0,\n",
              "       2, 1, 7, 2, 3, 5, 6, 2, 6, 5, 7, 6, 4, 1, 5, 8, 4, 3, 5, 5, 0, 4,\n",
              "       0, 9, 9, 4, 5, 0, 5, 7, 1, 7, 3, 3, 4, 8, 4, 6, 5, 1, 9, 6, 1, 3,\n",
              "       2, 0, 2, 3, 0, 4, 7, 9, 4, 3, 3, 7, 9, 4, 0, 1, 0, 0, 4, 1, 1, 8,\n",
              "       0, 0, 9, 0, 9, 7, 6, 0, 5, 7, 0, 3, 2, 9, 2, 9], dtype=int8)"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf=LogisticRegression(max_iter=1000)"
      ],
      "metadata": {
        "id": "gh4gvQj2grP_"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(x_train,y_train_1)"
      ],
      "metadata": {
        "id": "J41X41QGhEkB",
        "outputId": "f4654e85-a71a-4982-ed8b-9614e5c120e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000)"
            ],
            "text/html": [
              "<style>#sk-container-id-18 {color: black;background-color: white;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.predict([some_digit])"
      ],
      "metadata": {
        "id": "ArsmVdEFhr74",
        "outputId": "4467ca8f-904b-4966-cc88-920365836b7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False])"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "a=cross_val_score(clf,x_train,y_train_1,cv=3,scoring=\"accuracy\")"
      ],
      "metadata": {
        "id": "P3pjJjQ7h6aI"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.mean()"
      ],
      "metadata": {
        "id": "RUuWYgxriLMD",
        "outputId": "d00eec2a-dd9e-4d29-c066-7e8d1ee34eb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8139143399947093"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mq73YCxwitV_"
      },
      "execution_count": 196,
      "outputs": []
    }
  ]
}